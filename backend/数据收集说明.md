# 数据收集功能说明

## 📋 功能概述

数据收集模块可以自动从多个社交平台爬取产品评价数据，用于增强模型训练。支持微博、小红书、淘宝等平台。

## 🎯 主要特性

- ✅ **多平台支持**：微博、小红书、淘宝等
- ✅ **自动标注**：支持规则标注和AI标注
- ✅ **数据持久化**：自动保存收集的数据
- ✅ **智能去重**：自动去除重复数据
- ✅ **API接口**：支持手动触发收集和重新训练

## 🚀 使用方法

### 1. 配置环境变量

在 `.env` 文件或环境变量中设置：

```bash
# 启用自动数据收集（启动时自动收集）
AUTO_COLLECT_DATA=true

# 设置收集关键词（逗号分隔）
COLLECT_KEYWORDS=商品评价,产品评论,购物体验,商品质量,服务态度
```

### 2. 自动收集（启动时）

如果设置了 `AUTO_COLLECT_DATA=true`，服务启动时会自动收集数据：

```bash
export AUTO_COLLECT_DATA=true
export COLLECT_KEYWORDS=商品评价,产品评论
python app.py
```

### 3. 手动触发收集（API）

**接口**: `POST /api/collect-data`

**请求示例**:
```json
{
  "keywords": ["商品评价", "产品评论"],
  "count_per_keyword": 20,
  "use_ai_labeling": true
}
```

**响应示例**:
```json
{
  "success": true,
  "message": "成功收集 60 条数据",
  "statistics": {
    "total": 60,
    "sentiment_distribution": {
      "positive": 25,
      "negative": 20,
      "neutral": 15
    }
  },
  "note": "数据已保存，重启服务后会自动加载用于训练"
}
```

### 4. 重新训练模型

收集数据后，可以调用API重新训练模型：

**接口**: `POST /api/retrain`

**响应示例**:
```json
{
  "success": true,
  "message": "模型重新训练成功",
  "training_data_count": 140
}
```

## 📊 数据流程

```
启动/API触发
  ↓
数据收集模块
  ↓
┌─────────────────┐
│ 多平台数据收集   │
│ - 微博          │
│ - 小红书        │
│ - 淘宝          │
└─────────────────┘
  ↓
┌─────────────────┐
│ 情感标注         │
│ - 规则标注       │
│ - AI标注(可选)   │
└─────────────────┘
  ↓
数据去重
  ↓
保存到文件
  ↓
合并到训练数据
  ↓
重新训练模型（可选）
```

## 🔧 标注方式

### 1. 规则标注（默认）

使用关键词匹配规则进行标注：

- **正面关键词**: 好、棒、满意、推荐、喜欢、不错等
- **负面关键词**: 差、坏、不满意、不推荐、失望、垃圾等
- **中性**: 其他情况

### 2. AI标注（可选）

使用AI模型进行更准确的标注：

```json
{
  "use_ai_labeling": true
}
```

**优势**:
- 更准确的标注
- 理解上下文
- 处理复杂表达

**注意**: 需要配置AI API密钥

## 📁 数据存储

收集的数据保存在 `collected_training_data.json`：

```json
[
  {
    "text": "这个商品质量很好，非常满意！",
    "label": "positive"
  },
  {
    "text": "质量差，不推荐",
    "label": "negative"
  }
]
```

## 🎨 实际爬取实现

当前版本使用**模拟数据**，实际使用时需要：

### 1. 微博

**方法1**: 使用微博开放平台API
```python
# 需要申请API密钥
api_key = "your_weibo_api_key"
# 调用微博搜索API
```

**方法2**: 使用爬虫框架（注意遵守robots.txt）
```python
import scrapy
# 使用Scrapy框架爬取
```

### 2. 小红书

**方法1**: 使用官方API（如果有）
**方法2**: 使用爬虫框架
```python
import requests
from bs4 import BeautifulSoup
# 解析HTML获取评论
```

### 3. 淘宝

**方法1**: 使用淘宝开放平台API
```python
# 使用淘宝API获取商品评论
```

**方法2**: 爬取公开评论页面

## ⚠️ 注意事项

### 1. 法律合规

- ✅ 遵守各平台的robots.txt
- ✅ 遵守平台使用条款
- ✅ 不要过度频繁请求
- ✅ 仅收集公开数据

### 2. 反爬虫

- 设置合理的请求间隔
- 使用代理IP（如需要）
- 模拟真实浏览器请求头
- 处理验证码（如需要）

### 3. 数据质量

- 过滤广告和垃圾信息
- 去除重复数据
- 验证数据有效性
- 平衡各类别样本数量

### 4. 性能考虑

- 数据收集会增加启动时间
- 建议异步收集或定时任务
- 限制每次收集数量
- 使用缓存机制

## 🔄 扩展开发

### 添加新平台

在 `data_collector.py` 中添加新方法：

```python
def collect_new_platform(self, keyword: str, count: int = 20):
    """收集新平台数据"""
    # 实现爬取逻辑
    data = []
    # ... 爬取代码 ...
    return data
```

在 `collect_all_platforms` 中调用：

```python
new_platform_data = self.collect_new_platform(keyword, count_per_keyword)
all_data.extend(new_platform_data)
```

### 改进标注算法

可以集成更先进的标注方法：

1. **使用预训练模型**: 如BERT、RoBERTa
2. **半监督学习**: 结合少量标注数据
3. **主动学习**: 选择最有价值的样本标注

## 📈 效果评估

收集数据后，可以通过以下方式评估效果：

1. **模型准确率**: 对比收集前后的准确率
2. **数据分布**: 检查各类别数据平衡性
3. **交叉验证**: 使用验证集测试模型性能

## 🎯 最佳实践

1. **定期收集**: 设置定时任务定期收集新数据
2. **增量训练**: 只使用新数据增量训练，避免全量重训
3. **数据验证**: 收集后人工抽样验证数据质量
4. **版本管理**: 保存不同版本的数据集，便于回滚
5. **监控指标**: 监控收集数据量和质量

---

**提示**: 当前版本使用模拟数据，实际部署时需要替换为真实的爬取逻辑。

